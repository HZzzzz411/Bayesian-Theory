---
title: "Introduction to Bayesian Statistics"
---
# 1.1 Introduction to Bayesian Statistics
## Bayesian vs. Classical Inference
$\theta$ : population parameter that we wish to make inference

$X$ : random variables, observe the values $x = {x_1,...,x_n}$
- **Classical Approach**:
  - $\theta$ are considered fixed but unknown constants.
  - Inference is based on the likelihood function $f(\theta;x) \equiv f(x|\theta)$
  - The classical approach looks at the distribution of the data given the parameter, to estimate the parameter $\theta$.

- **Bayesian Approach**:
  - Parameters are treated as random variables with unknown distributions $\pi(\theta|x)$.
  - Inference is based on the posterior distribution $\pi(\theta|x)$, which represents the updated beliefs about the parameters given the data.
  - Bayesian Approach look at the distribution of the parameter, given the data
  - The posterior distribution combines prior distribution and data information (likelihood).

### Prior & Posterior Distributions

- **Prior Distribution**: Represents initial beliefs about the parameters **before observing any data**.
  - Can be based on expert knowledge, historical data, or subjective judgment.

- **Posterior Distribution**: Updated distribution of the parameters after incorporating the observed data.
  - Combines prior knowledge and data information through Bayes' Theorem.

### Advantages and Criticisms of Bayesian Methods

- **Advantages**:
  - Incorporates prior knowledge, drawing inference from combined knowledge.
  - Provides a natural way to update beliefs as new data become available.

- **Criticisms**:
  - The choice of prior distribution is subjective and can influence the results.
  - Different priors can lead to different inferences, which some view as a drawback.
